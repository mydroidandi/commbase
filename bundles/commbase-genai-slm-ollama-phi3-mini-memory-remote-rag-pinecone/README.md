[![Python Package using Conda](https://github.com/mydroidandi/commbase/actions/workflows/python-package-conda.yml/badge.svg)](https://github.com/mydroidandi/commbase/actions/workflows/python-package-conda.yml)
[![Python Version](https://img.shields.io/badge/Python-3.10%20%7C%203.11%20%7C%203.12-blue)](https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12-blue)

# commbase-genai-slm-ollama-phi3-mini-memory-remote-rag-pinecone

<img alt="commbase-genai-slm-ollama-phi3-mini-memory-remote-rag-pinecone" src="commbase-genai-slm-ollama-phi3-mini-memory-remote-rag-pinecone.jpg?raw=true" width="512" height="640" />

Interacts with the Commbase platform by generating AI-driven responses using the Ollama API with the Phi3 mini model from Microsoft. This is a heavyweight implementation with memory for language generation, featuring remote RAG and Pinecone for persistent memory.

## Examples

Detailed information about examples can be found in the corresponding [`examples`](./examples) directory.

## Contributors

Thanks to the following people who have contributed to this project:

* [@estebanways](https://github.com/estebanways)

## Contact

If you want to contact us you can reach us at <stv.herrera@gmail.com>.

## License

This project uses the following license: [`License`](./COPYING).
